# -*- coding: utf-8 -*-
"""
ä»»åŠ¡ï¼šåŸºäºç‰©ç†è§„å¾‹æ„å»ºæ°”è±¡-åœ°å½¢äº¤äº’ç‰¹å¾
åŠŸèƒ½ï¼š
  1. ä»å·²ç­›é€‰çš„TIGGEå’ŒDEMæ•°æ®é›†åŠ è½½æ•°æ®
  2. åŸºäºå¤§æ°”ç‰©ç†æ–¹ç¨‹æ„å»º5ä¸ªæ ¸å¿ƒäº¤äº’ç‰¹å¾
  3. æ ‡å‡†åŒ–æ‰€æœ‰ç‰¹å¾åˆ°[0,1]èŒƒå›´
  4. ä¿å­˜ä¸ºè®­ç»ƒé›†/éªŒè¯é›†/æµ‹è¯•é›†ï¼ˆNetCDFæ ¼å¼ï¼‰
"""

import os
import numpy as np
import xarray as xr
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler
import joblib
import gc
import time
from datetime import datetime
from pathlib import Path

# ==================== è·¯å¾„è®¾ç½® ====================
# è¾“å…¥è·¯å¾„ï¼ˆå·²ç­›é€‰çš„æ•°æ®é›†ï¼‰
input_data_path = {
    "ERA5": r"E:\yym2\qixiang\Obs_PDF\processed_data_v2_features\ERA5\ERA5_final_2021_2024.nc",
    "TIGGE": r"E:\yym2\qixiang\Obs_PDF\processed_data_v2_features\TIGGE\TIGGE_final_2021_2024.nc",
    "DEM": r"E:\yym2\qixiang\Obs_PDF\processed_data_v2_features\DEM\DEM_final.nc"
}

# è¾“å‡ºè·¯å¾„
output_path = Path(r"E:\yym2\qixiang\Obs_PDF\final")
output_path.mkdir(parents=True, exist_ok=True)


# ==================== è¾…åŠ©å‡½æ•° ====================
def log_progress(message, start_time=None):
    """è®°å½•è¿›åº¦ä¿¡æ¯"""
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    if start_time:
        elapsed = time.time() - start_time
        elapsed_min = elapsed // 60
        elapsed_sec = elapsed % 60
        print(f"[{timestamp}] {message} (è€—æ—¶: {int(elapsed_min)}åˆ†{int(elapsed_sec)}ç§’)")
    else:
        print(f"[{timestamp}] {message}")
    return time.time()


def print_memory_usage(label=""):
    """æ‰“å°å½“å‰å†…å­˜ä½¿ç”¨æƒ…å†µ"""
    import psutil
    process = psutil.Process(os.getpid())
    memory_info = process.memory_info()
    memory_gb = memory_info.rss / (1024 * 1024 * 1024)
    print(f"å†…å­˜ä½¿ç”¨ {label}: {memory_gb:.2f} GB")


# ==================== ç‰©ç†äº¤äº’ç‰¹å¾æ„å»º ====================
def build_physics_based_interactions(tigge_df, dem_df):
    """
    åŸºäºå¤§æ°”ç‰©ç†æ–¹ç¨‹æ„å»º5ä¸ªæ ¸å¿ƒäº¤äº’ç‰¹å¾

    å‚æ•°:
        tigge_df: DataFrame, åŒ…å«TIGGEæ°”è±¡å‚æ•°
        dem_df: DataFrame, åŒ…å«DEMåœ°å½¢å‚æ•°

    è¿”å›:
        interactions_df: DataFrame, åŒ…å«5ä¸ªç‰©ç†äº¤äº’ç‰¹å¾
    """
    log_progress("å¼€å§‹æ„å»ºç‰©ç†äº¤äº’ç‰¹å¾...")

    interactions = {}

    # ========== ç‰¹å¾1: é£é€Ÿ-åœ°å½¢èµ·ä¼äº¤äº’ (æœ€é‡è¦) ==========
    # ç‰©ç†æ„ä¹‰: åœ°å½¢ç²—ç³™åº¦å¯¹é£é€Ÿçš„é˜»åŠ›æ•ˆåº”(wind speed,relief)
    # å…¬å¼: wind_terrain_drag = tigge_wind_speed Ã— (1 + Î± Ã— relief)
    # Î±ä¸ºåœ°å½¢é˜»åŠ›ç³»æ•°ï¼Œè¿™é‡Œä½¿ç”¨reliefçš„å½’ä¸€åŒ–å€¼ä½œä¸ºæƒé‡
    log_progress("æ„å»ºç‰¹å¾1: é£é€Ÿ-åœ°å½¢èµ·ä¼äº¤äº’ (wind_terrain_drag)")

    # å½’ä¸€åŒ–reliefåˆ°åˆç†èŒƒå›´ï¼Œé¿å…æç«¯å€¼
    relief_normalized = (tigge_df['tigge_wind_speed'].values *
                         (1 + 0.1 * dem_df['relief'].values / dem_df['relief'].values.std()))
    interactions['wind_terrain_drag'] = relief_normalized
    print(f"   wind_terrain_drag: å‡å€¼={relief_normalized.mean():.4f}, æ ‡å‡†å·®={relief_normalized.std():.4f}")

    # ========== ç‰¹å¾2: é£çŸ¢é‡-å¡å‘äº¤äº’ (æ¬¡é‡è¦) ==========
    # ç‰©ç†æ„ä¹‰: é£é€ŸçŸ¢é‡ä¸åœ°å½¢æœå‘çš„è€¦åˆï¼Œå†³å®šé£çš„é®æŒ¡å’Œå¼•å¯¼æ•ˆåº”ï¼ˆu10,v10,slope)
    # å…¬å¼: wind_aspect_coupling = sqrt((u10Ã—cos(aspect))Â² + (v10Ã—sin(aspect))Â²)
    # aspectè½¬æ¢ä¸ºå¼§åº¦ï¼Œè®¡ç®—é£é€Ÿåˆ†é‡åœ¨å¡å‘ä¸Šçš„æŠ•å½±
    log_progress("æ„å»ºç‰¹å¾2: é£çŸ¢é‡-å¡å‘äº¤äº’ (wind_aspect_coupling)")

    aspect_rad = np.deg2rad(dem_df['aspect'].values)
    u10 = tigge_df['u10'].values
    v10 = tigge_df['v10'].values

    # è®¡ç®—é£é€Ÿåœ¨å¡å‘ä¸Šçš„æœ‰æ•ˆåˆ†é‡ï¼ˆè€ƒè™‘é£å‘ä¸å¡å‘çš„å¤¹è§’ï¼‰
    wind_projection = np.sqrt(
        (u10 * np.cos(aspect_rad)) ** 2 +
        (v10 * np.sin(aspect_rad)) ** 2
    )
    interactions['wind_aspect_coupling'] = wind_projection
    print(f"   wind_aspect_coupling: å‡å€¼={wind_projection.mean():.4f}, æ ‡å‡†å·®={wind_projection.std():.4f}")

    # ========== ç‰¹å¾3: æ¸©åº¦-æµ·æ‹”å‚ç›´é€’å‡ ==========
    # ç‰©ç†æ„ä¹‰: å¤§æ°”æ¸©åº¦å‚ç›´é€’å‡ç‡ (çº¦6.5K/km)ï¼Œåæ˜ å±€åœ°çƒ­åŠ›æ¡ä»¶(t2m,elevation)
    # å…¬å¼: thermal_lapse = t2m Ã— exp(-Î³ Ã— elevation / 1000)
    # Î³ä¸ºå¹²ç»çƒ­é€’å‡ç‡ç³»æ•° (çº¦0.0065 K/m)
    log_progress("æ„å»ºç‰¹å¾3: æ¸©åº¦-æµ·æ‹”å‚ç›´é€’å‡ (thermal_lapse)")

    gamma = 0.0065  # å¹²ç»çƒ­é€’å‡ç‡ (K/m)
    elevation_km = dem_df['elevation'].values / 1000.0  # è½¬æ¢ä¸ºkm
    t2m = tigge_df['t2m'].values

    # è€ƒè™‘æµ·æ‹”å¯¹æ¸©åº¦çš„ä¿®æ­£
    thermal_correction = t2m * np.exp(-gamma * elevation_km)
    interactions['thermal_lapse'] = thermal_correction
    print(f"   thermal_lapse: å‡å€¼={thermal_correction.mean():.4f}, æ ‡å‡†å·®={thermal_correction.std():.4f}")

    # ========== ç‰¹å¾4: æ°”å‹-æµ·æ‹”ä¿®æ­£ ==========
    # ç‰©ç†æ„ä¹‰: é™åŠ›å­¦æ–¹ç¨‹çš„åœ°å½¢ä¿®æ­£ï¼Œæ°”å‹éšæµ·æ‹”çš„æŒ‡æ•°è¡°å‡(sp,elevation)
    # å…¬å¼: pressure_elevation = sp Ã— exp(-elevation / H)
    # Hä¸ºæ ‡é«˜ (çº¦8500m)
    log_progress("æ„å»ºç‰¹å¾4: æ°”å‹-æµ·æ‹”ä¿®æ­£ (pressure_elevation)")

    H = 8500.0  # å¤§æ°”æ ‡é«˜ (m)
    sp = tigge_df['sp'].values
    elevation = dem_df['elevation'].values

    # æ°”å‹çš„æµ·æ‹”ä¿®æ­£ï¼ˆæ°”å‹éšæµ·æ‹”æŒ‡æ•°è¡°å‡ï¼‰
    pressure_corrected = sp * np.exp(-elevation / H)
    interactions['pressure_elevation'] = pressure_corrected
    print(f"   pressure_elevation: å‡å€¼={pressure_corrected.mean():.4f}, æ ‡å‡†å·®={pressure_corrected.std():.4f}")

    # ========== ç‰¹å¾5: è¾å°„-å¡å‘çƒ­åŠ›é©±åŠ¨ ==========
    # ç‰©ç†æ„ä¹‰: å¡å‘å¯¹å¤ªé˜³è¾å°„çš„è°ƒåˆ¶ï¼Œé©±åŠ¨å±€åœ°çƒ­åŠ›ç¯æµ(ssr,slope)
    # å…¬å¼: radiation_aspect = ssr Ã— cos(aspect - 180Â°)
    # å—å¡ï¼ˆaspectâ‰ˆ180Â°ï¼‰è·å¾—æœ€å¤§è¾å°„ï¼ŒåŒ—å¡æœ€å°
    log_progress("æ„å»ºç‰¹å¾5: è¾å°„-å¡å‘çƒ­åŠ›é©±åŠ¨ (radiation_aspect)")

    ssr = tigge_df['ssr'].values
    aspect_rad = np.deg2rad(dem_df['aspect'].values)

    # è®¡ç®—å¡å‘å¯¹è¾å°„çš„å¢å¼º/å‡å¼±ç³»æ•°
    # aspect=180Â°(å—å¡)æ—¶cos(0)=1æœ€å¤§ï¼Œaspect=0Â°(åŒ—å¡)æ—¶cos(180Â°)=-1æœ€å°
    aspect_factor = np.cos(aspect_rad - np.pi)  # ç›¸å¯¹å—å‘çš„è¾å°„ç³»æ•°
    radiation_modulated = ssr * (1 + aspect_factor) / 2  # å½’ä¸€åŒ–åˆ°[0, ssr]
    interactions['radiation_aspect'] = radiation_modulated
    print(f"   radiation_aspect: å‡å€¼={radiation_modulated.mean():.4f}, æ ‡å‡†å·®={radiation_modulated.std():.4f}")

    # è½¬æ¢ä¸ºDataFrame
    interactions_df = pd.DataFrame(interactions)

    log_progress(f"ç‰©ç†äº¤äº’ç‰¹å¾æ„å»ºå®Œæˆï¼Œå…±ç”Ÿæˆ {len(interactions)} ä¸ªç‰¹å¾")
    print(f"\näº¤äº’ç‰¹å¾ç»Ÿè®¡æ‘˜è¦:")
    print(interactions_df.describe())

    return interactions_df


# ==================== æ•°æ®åŠ è½½å’Œå¤„ç† ====================
def load_and_process_data():
    """åŠ è½½æ•°æ®å¹¶æ„å»ºäº¤äº’ç‰¹å¾"""
    start_time = time.time()
    log_progress("=" * 100)
    log_progress("å¼€å§‹æ•°æ®åŠ è½½å’Œå¤„ç†æµç¨‹")
    log_progress("=" * 100)
    print_memory_usage("å¤„ç†å‰")

    # 1. åŠ è½½åŸå§‹æ•°æ®
    log_progress("æ­¥éª¤1: åŠ è½½ERA5ã€TIGGEã€DEMæ•°æ®...")
    era5 = xr.open_dataset(input_data_path["ERA5"])
    tigge = xr.open_dataset(input_data_path["TIGGE"])
    dem = xr.open_dataset(input_data_path["DEM"])

    log_progress(f"æ•°æ®åŠ è½½å®Œæˆ:")
    print(f"   ERA5æ—¶é—´èŒƒå›´: {era5.time.values.min()} è‡³ {era5.time.values.max()}")
    print(f"   TIGGEæ—¶é—´èŒƒå›´: {tigge.time.values.min()} è‡³ {tigge.time.values.max()}")
    print(f"   DEMç©ºé—´èŒƒå›´: lat({dem.lat.values.min():.2f}, {dem.lat.values.max():.2f}), "
          f"lon({dem.lon.values.min():.2f}, {dem.lon.values.max():.2f})")

    # 2. åˆå¹¶æ•°æ®é›†
    log_progress("æ­¥éª¤2: åˆå¹¶æ•°æ®é›†...")
    merged = xr.merge([era5, tigge, dem], join='inner')
    print(f"   åˆå¹¶åæ•°æ®å½¢çŠ¶: {dict(merged.dims)}")

    # 3. æŒ‰å¹´ä»½åˆ’åˆ†æ•°æ®
    log_progress("æ­¥éª¤3: æŒ‰å¹´ä»½åˆ’åˆ†æ•°æ®é›†...")
    merged['time'] = pd.to_datetime(merged.time.values)

    train_data = merged.sel(time=slice('2021-01-01', '2022-12-31'))
    val_data = merged.sel(time=slice('2023-01-01', '2023-12-31'))
    test_data = merged.sel(time=slice('2024-01-01', '2024-12-31'))

    print(f"   è®­ç»ƒé›†(2021-2022): {len(train_data.time)} æ—¶é—´ç‚¹")
    print(f"   éªŒè¯é›†(2023): {len(val_data.time)} æ—¶é—´ç‚¹")
    print(f"   æµ‹è¯•é›†(2024): {len(test_data.time)} æ—¶é—´ç‚¹")

    # 4. è½¬æ¢ä¸ºDataFrame
    log_progress("æ­¥éª¤4: è½¬æ¢ä¸ºDataFrameæ ¼å¼...")
    train_df = train_data.to_dataframe().reset_index().dropna(subset=['era5_wind_speed'])
    val_df = val_data.to_dataframe().reset_index().dropna(subset=['era5_wind_speed'])
    test_df = test_data.to_dataframe().reset_index().dropna(subset=['era5_wind_speed'])

    print(f"   è®­ç»ƒé›†æ ·æœ¬æ•°: {len(train_df)}")
    print(f"   éªŒè¯é›†æ ·æœ¬æ•°: {len(val_df)}")
    print(f"   æµ‹è¯•é›†æ ·æœ¬æ•°: {len(test_df)}")

    # é‡Šæ”¾å†…å­˜
    del merged, train_data, val_data, test_data, era5
    gc.collect()
    print_memory_usage("DataFrameè½¬æ¢å")

    log_progress("æ•°æ®åŠ è½½å’Œå¤„ç†å®Œæˆ", start_time)
    return train_df, val_df, test_df, tigge, dem


def extract_and_standardize_features(train_df, val_df, test_df, tigge, dem):
    """æå–ç‰¹å¾ã€æ„å»ºäº¤äº’ç‰¹å¾å¹¶æ ‡å‡†åŒ–"""
    start_time = time.time()
    log_progress("=" * 100)
    log_progress("å¼€å§‹ç‰¹å¾æå–å’Œæ ‡å‡†åŒ–")
    log_progress("=" * 100)

    # 1. å®šä¹‰ç‰¹å¾åˆ—è¡¨
    log_progress("æ­¥éª¤1: å®šä¹‰ç‰¹å¾åˆ—è¡¨...")

    # TIGGEæ°”è±¡ç‰¹å¾ï¼ˆ10ä¸ªï¼‰
    tigge_features = [
        'tigge_wind_speed',  # TIGGEé¢„æŠ¥é£é€Ÿ
        'orog',  # åœ°å½¢é«˜åº¦
        'sm',  # åœŸå£¤æ¹¿åº¦
        'lsm',  # é™†æµ·æ©è†œ
        'v10',  # 10ç±³Vé£åˆ†é‡
        'ssr',  # åœ°è¡¨å‡€çŸ­æ³¢è¾å°„
        'u10',  # 10ç±³Ué£åˆ†é‡
        'msl',  # å¹³å‡æµ·å¹³é¢æ°”å‹
        't2m',  # 2ç±³æ¸©åº¦
        'sp'  # åœ°è¡¨æ°”å‹
    ]

    # DEMåœ°å½¢ç‰¹å¾ï¼ˆ3ä¸ªï¼‰
    dem_features = ['relief', 'elevation', 'aspect']

    # æ—¶é—´ç‰¹å¾
    time_features_list = ['hour', 'day', 'month', 'season']

    # éªŒè¯ç‰¹å¾æ˜¯å¦å­˜åœ¨
    for feat in tigge_features:
        if feat not in train_df.columns:
            print(f"   è­¦å‘Š: TIGGEç‰¹å¾ '{feat}' ä¸åœ¨æ•°æ®é›†ä¸­")

    for feat in dem_features:
        if feat not in train_df.columns:
            print(f"   è­¦å‘Š: DEMç‰¹å¾ '{feat}' ä¸åœ¨æ•°æ®é›†ä¸­")

    print(f"   TIGGEç‰¹å¾: {len(tigge_features)}ä¸ª")
    print(f"   DEMç‰¹å¾: {len(dem_features)}ä¸ª")
    print(f"   æ—¶é—´ç‰¹å¾: {len(time_features_list)}ä¸ª")

    # 2. æ„å»ºç‰©ç†äº¤äº’ç‰¹å¾
    log_progress("æ­¥éª¤2: æ„å»ºç‰©ç†äº¤äº’ç‰¹å¾...")

    train_interactions = build_physics_based_interactions(
        train_df[tigge_features], train_df[dem_features]
    )
    val_interactions = build_physics_based_interactions(
        val_df[tigge_features], val_df[dem_features]
    )
    test_interactions = build_physics_based_interactions(
        test_df[tigge_features], test_df[dem_features]
    )

    interaction_features = list(train_interactions.columns)
    print(f"   ç”Ÿæˆäº¤äº’ç‰¹å¾: {len(interaction_features)}ä¸ª")
    for i, feat in enumerate(interaction_features, 1):
        print(f"      {i}. {feat}")

    # 3. æ ‡å‡†åŒ–TIGGEç‰¹å¾
    log_progress("æ­¥éª¤3: æ ‡å‡†åŒ–TIGGEç‰¹å¾...")
    scaler_tigge = MinMaxScaler(feature_range=(0, 1))

    X_train_tigge = scaler_tigge.fit_transform(train_df[tigge_features].fillna(0))
    X_val_tigge = scaler_tigge.transform(val_df[tigge_features].fillna(0))
    X_test_tigge = scaler_tigge.transform(test_df[tigge_features].fillna(0))

    print(f"   TIGGEç‰¹å¾æ ‡å‡†åŒ–å®Œæˆ: {X_train_tigge.shape}")

    # 4. æ ‡å‡†åŒ–DEMç‰¹å¾
    log_progress("æ­¥éª¤4: æ ‡å‡†åŒ–DEMç‰¹å¾...")
    scaler_dem = MinMaxScaler(feature_range=(0, 1))

    X_train_dem = scaler_dem.fit_transform(train_df[dem_features].fillna(0))
    X_val_dem = scaler_dem.transform(val_df[dem_features].fillna(0))
    X_test_dem = scaler_dem.transform(test_df[dem_features].fillna(0))

    print(f"   DEMç‰¹å¾æ ‡å‡†åŒ–å®Œæˆ: {X_train_dem.shape}")

    # 5. æ ‡å‡†åŒ–äº¤äº’ç‰¹å¾
    log_progress("æ­¥éª¤5: æ ‡å‡†åŒ–äº¤äº’ç‰¹å¾...")
    scaler_interaction = MinMaxScaler(feature_range=(0, 1))

    X_train_interaction = scaler_interaction.fit_transform(train_interactions)
    X_val_interaction = scaler_interaction.transform(val_interactions)
    X_test_interaction = scaler_interaction.transform(test_interactions)

    print(f"   äº¤äº’ç‰¹å¾æ ‡å‡†åŒ–å®Œæˆ: {X_train_interaction.shape}")

    # 6. æ ‡å‡†åŒ–ç›®æ ‡å˜é‡
    log_progress("æ­¥éª¤6: æ ‡å‡†åŒ–ç›®æ ‡å˜é‡...")
    scaler_y = MinMaxScaler(feature_range=(0, 1))

    y_train = scaler_y.fit_transform(train_df['era5_wind_speed'].values.reshape(-1, 1)).flatten()
    y_val = scaler_y.transform(val_df['era5_wind_speed'].values.reshape(-1, 1)).flatten()
    y_test = scaler_y.transform(test_df['era5_wind_speed'].values.reshape(-1, 1)).flatten()

    print(f"   ç›®æ ‡å˜é‡æ ‡å‡†åŒ–å®Œæˆ: {y_train.shape}")

    # 7. å¤„ç†æ—¶é—´ç‰¹å¾
    log_progress("æ­¥éª¤7: å¤„ç†æ—¶é—´ç‰¹å¾...")
    time_features_dict = {}

    for phase, df in [('train', train_df), ('val', val_df), ('test', test_df)]:
        df['time'] = pd.to_datetime(df['time'])
        time_cols = pd.DataFrame({
            'year': df['time'].dt.year,
            'month': df['time'].dt.month,
            'day': df['time'].dt.day,
            'hour': df['time'].dt.hour,
            'season': df['time'].dt.month % 12 // 3 + 1
        })
        time_features_dict[phase] = time_cols.values.astype(np.int64)

    print(f"   æ—¶é—´ç‰¹å¾æå–å®Œæˆ")

    # 8. ä¿å­˜æ ‡å‡†åŒ–å™¨
    log_progress("æ­¥éª¤8: ä¿å­˜æ ‡å‡†åŒ–å™¨...")
    joblib.dump(scaler_tigge, output_path / 'tigge_feature_scaler.pkl')
    joblib.dump(scaler_dem, output_path / 'dem_feature_scaler.pkl')
    joblib.dump(scaler_interaction, output_path / 'interaction_feature_scaler.pkl')
    joblib.dump(scaler_y, output_path / 'target_scaler.pkl')

    print(f"   æ ‡å‡†åŒ–å™¨å·²ä¿å­˜è‡³: {output_path}")

    # é‡Šæ”¾å†…å­˜
    del train_df, val_df, test_df
    gc.collect()
    print_memory_usage("ç‰¹å¾æå–å")

    log_progress("ç‰¹å¾æå–å’Œæ ‡å‡†åŒ–å®Œæˆ", start_time)

    return (X_train_tigge, X_val_tigge, X_test_tigge,
            X_train_dem, X_val_dem, X_test_dem,
            X_train_interaction, X_val_interaction, X_test_interaction,
            y_train, y_val, y_test,
            time_features_dict,
            tigge_features, dem_features, interaction_features)


def save_final_datasets(X_train_tigge, X_val_tigge, X_test_tigge,
                        X_train_dem, X_val_dem, X_test_dem,
                        X_train_interaction, X_val_interaction, X_test_interaction,
                        y_train, y_val, y_test,
                        time_features_dict,
                        tigge_features, dem_features, interaction_features):
    """ä¿å­˜æœ€ç»ˆæ•°æ®é›†ä¸ºNetCDFæ ¼å¼"""
    start_time = time.time()
    log_progress("=" * 100)
    log_progress("å¼€å§‹ä¿å­˜æœ€ç»ˆæ•°æ®é›†")
    log_progress("=" * 100)

    # æ•°æ®ç»´åº¦éªŒè¯
    log_progress("æ­¥éª¤1: éªŒè¯æ•°æ®ç»´åº¦...")
    print(f"   TIGGEç‰¹å¾: Train{X_train_tigge.shape}, Val{X_val_tigge.shape}, Test{X_test_tigge.shape}")
    print(f"   DEMç‰¹å¾: Train{X_train_dem.shape}, Val{X_val_dem.shape}, Test{X_test_dem.shape}")
    print(
        f"   äº¤äº’ç‰¹å¾: Train{X_train_interaction.shape}, Val{X_val_interaction.shape}, Test{X_test_interaction.shape}")
    print(f"   ç›®æ ‡å˜é‡: Train{y_train.shape}, Val{y_val.shape}, Test{y_test.shape}")

    time_feature_labels = ['year', 'month', 'day', 'hour', 'season']

    # åˆ›å»ºè®­ç»ƒé›†
    log_progress("æ­¥éª¤2: åˆ›å»ºè®­ç»ƒé›†æ•°æ®é›†...")
    train_ds = xr.Dataset(
        data_vars={
            "tigge_features": (["sample", "tigge_feature"], X_train_tigge),
            "dem_features": (["sample", "dem_feature"], X_train_dem),
            "interaction_features": (["sample", "interaction_feature"], X_train_interaction),
            "target": (["sample"], y_train),
            "time_features": (["sample", "time_feature"], time_features_dict['train'])
        },
        coords={
            "sample": np.arange(X_train_tigge.shape[0]),
            "tigge_feature": tigge_features,
            "dem_feature": dem_features,
            "interaction_feature": interaction_features,
            "time_feature": time_feature_labels
        },
        attrs={
            "description": "è®­ç»ƒé›†æ•°æ®ï¼ˆ2021-2022ï¼‰",
            "created_date": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "tigge_features_count": len(tigge_features),
            "dem_features_count": len(dem_features),
            "interaction_features_count": len(interaction_features),
            "total_samples": X_train_tigge.shape[0]
        }
    )

    # åˆ›å»ºéªŒè¯é›†
    log_progress("æ­¥éª¤3: åˆ›å»ºéªŒè¯é›†æ•°æ®é›†...")
    val_ds = xr.Dataset(
        data_vars={
            "tigge_features": (["sample", "tigge_feature"], X_val_tigge),
            "dem_features": (["sample", "dem_feature"], X_val_dem),
            "interaction_features": (["sample", "interaction_feature"], X_val_interaction),
            "target": (["sample"], y_val),
            "time_features": (["sample", "time_feature"], time_features_dict['val'])
        },
        coords={
            "sample": np.arange(X_val_tigge.shape[0]),
            "tigge_feature": tigge_features,
            "dem_feature": dem_features,
            "interaction_feature": interaction_features,
            "time_feature": time_feature_labels
        },
        attrs={
            "description": "éªŒè¯é›†æ•°æ®ï¼ˆ2023ï¼‰",
            "created_date": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "tigge_features_count": len(tigge_features),
            "dem_features_count": len(dem_features),
            "interaction_features_count": len(interaction_features),
            "total_samples": X_val_tigge.shape[0]
        }
    )

    # åˆ›å»ºæµ‹è¯•é›†
    log_progress("æ­¥éª¤4: åˆ›å»ºæµ‹è¯•é›†æ•°æ®é›†...")
    test_ds = xr.Dataset(
        data_vars={
            "tigge_features": (["sample", "tigge_feature"], X_test_tigge),
            "dem_features": (["sample", "dem_feature"], X_test_dem),
            "interaction_features": (["sample", "interaction_feature"], X_test_interaction),
            "target": (["sample"], y_test),
            "time_features": (["sample", "time_feature"], time_features_dict['test'])
        },
        coords={
            "sample": np.arange(X_test_tigge.shape[0]),
            "tigge_feature": tigge_features,
            "dem_feature": dem_features,
            "interaction_feature": interaction_features,
            "time_feature": time_feature_labels
        },
        attrs={
            "description": "æµ‹è¯•é›†æ•°æ®ï¼ˆ2024ï¼‰",
            "created_date": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "tigge_features_count": len(tigge_features),
            "dem_features_count": len(dem_features),
            "interaction_features_count": len(interaction_features),
            "total_samples": X_test_tigge.shape[0]
        }
    )

    # ä¿å­˜æ•°æ®é›†
    try:
        log_progress("æ­¥éª¤5: ä¿å­˜æ•°æ®é›†åˆ°ç£ç›˜...")

        train_file = output_path / "train.nc"
        val_file = output_path / "val.nc"
        test_file = output_path / "test.nc"

        train_ds.to_netcdf(train_file)
        print(f"   âœ“ è®­ç»ƒé›†å·²ä¿å­˜: {train_file}")

        val_ds.to_netcdf(val_file)
        print(f"   âœ“ éªŒè¯é›†å·²ä¿å­˜: {val_file}")

        test_ds.to_netcdf(test_file)
        print(f"   âœ“ æµ‹è¯•é›†å·²ä¿å­˜: {test_file}")

        # è¾“å‡ºæ–‡ä»¶å¤§å°
        train_size = train_file.stat().st_size / (1024 ** 2)
        val_size = val_file.stat().st_size / (1024 ** 2)
        test_size = test_file.stat().st_size / (1024 ** 2)

        print(f"\n   æ–‡ä»¶å¤§å°:")
        print(f"      train.nc: {train_size:.2f} MB")
        print(f"      val.nc: {val_size:.2f} MB")
        print(f"      test.nc: {test_size:.2f} MB")
        print(f"      æ€»è®¡: {train_size + val_size + test_size:.2f} MB")

    except Exception as e:
        print(f"   âœ— ä¿å­˜æ•°æ®é›†æ—¶å‡ºé”™: {e}")
        raise

    log_progress("æ•°æ®é›†ä¿å­˜å®Œæˆ", start_time)

    return train_ds, val_ds, test_ds


def verify_final_datasets():
    """éªŒè¯ä¿å­˜çš„æ•°æ®é›†"""
    log_progress("=" * 100)
    log_progress("éªŒè¯ä¿å­˜çš„æ•°æ®é›†")
    log_progress("=" * 100)

    datasets = {
        "è®­ç»ƒé›†": output_path / "train.nc",
        "éªŒè¯é›†": output_path / "val.nc",
        "æµ‹è¯•é›†": output_path / "test.nc"
    }

    for name, path in datasets.items():
        print(f"\n{'=' * 80}")
        print(f"æ­£åœ¨éªŒè¯: {name}")
        print(f"{'=' * 80}")

        if not path.exists():
            print(f"   âœ— æ–‡ä»¶ä¸å­˜åœ¨: {path}")
            continue

        ds = xr.open_dataset(path)

        print(f"\nğŸ“ æ–‡ä»¶ä¿¡æ¯:")
        print(f"   è·¯å¾„: {path}")
        print(f"   å¤§å°: {path.stat().st_size / (1024 ** 2):.2f} MB")

        print(f"\nğŸ“ ç»´åº¦:")
        for dim, size in ds.dims.items():
            print(f"   {dim:<25}: {size:,}")

        print(f"\nğŸ“¦ æ•°æ®å˜é‡:")
        for var in ds.data_vars:
            print(f"   {var:<25}: {ds[var].dims} - {ds[var].shape}")

        print(f"\nğŸ·ï¸  åæ ‡å˜é‡:")
        for coord in ds.coords:
            if coord not in ds.dims:
                coord_data = ds.coords[coord]
                if coord_data.size <= 10:
                    print(f"   {coord:<25}: {coord_data.values.tolist()}")
                else:
                    print(f"   {coord:<25}: (å…± {coord_data.size} ä¸ªå€¼)")

        print(f"\nğŸ“Š å±æ€§ä¿¡æ¯:")
        for attr, value in ds.attrs.items():
            print(f"   {attr}: {value}")

        # æ•°æ®ç»Ÿè®¡
        print(f"\nğŸ“ˆ æ•°æ®ç»Ÿè®¡:")
        print(f"   ç›®æ ‡å˜é‡ (target):")
        target_data = ds['target'].values
        print(f"      æœ€å°å€¼: {target_data.min():.6f}")
        print(f"      æœ€å¤§å€¼: {target_data.max():.6f}")
        print(f"      å¹³å‡å€¼: {target_data.mean():.6f}")
        print(f"      æ ‡å‡†å·®: {target_data.std():.6f}")

        ds.close()

    log_progress("æ•°æ®é›†éªŒè¯å®Œæˆ")


# ==================== ä¸»æµç¨‹ ====================
def main():
    """ä¸»æµç¨‹å‡½æ•°"""
    total_start_time = time.time()

    print("\n" + "=" * 100)
    print("åŸºäºç‰©ç†è§„å¾‹çš„æ°”è±¡-åœ°å½¢äº¤äº’ç‰¹å¾æ„å»ºç³»ç»Ÿ".center(100))
    print("=" * 100)
    log_progress(f"å¼€å§‹æ‰§è¡Œ - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

    try:
        # æ­¥éª¤1: åŠ è½½å’Œå¤„ç†æ•°æ®
        log_progress("\nã€é˜¶æ®µ1/4ã€‘æ•°æ®åŠ è½½å’Œé¢„å¤„ç†")
        train_df, val_df, test_df, tigge, dem = load_and_process_data()

        # æ­¥éª¤2: æå–ç‰¹å¾ã€æ„å»ºäº¤äº’ç‰¹å¾å¹¶æ ‡å‡†åŒ–
        log_progress("\nã€é˜¶æ®µ2/4ã€‘ç‰¹å¾æå–å’Œæ ‡å‡†åŒ–")
        (X_train_tigge, X_val_tigge, X_test_tigge,
         X_train_dem, X_val_dem, X_test_dem,
         X_train_interaction, X_val_interaction, X_test_interaction,
         y_train, y_val, y_test,
         time_features_dict,
         tigge_features, dem_features, interaction_features) = extract_and_standardize_features(
            train_df, val_df, test_df, tigge, dem
        )

        # æ­¥éª¤3: ä¿å­˜æœ€ç»ˆæ•°æ®é›†
        log_progress("\nã€é˜¶æ®µ3/4ã€‘ä¿å­˜æœ€ç»ˆæ•°æ®é›†")
        train_ds, val_ds, test_ds = save_final_datasets(
            X_train_tigge, X_val_tigge, X_test_tigge,
            X_train_dem, X_val_dem, X_test_dem,
            X_train_interaction, X_val_interaction, X_test_interaction,
            y_train, y_val, y_test,
            time_features_dict,
            tigge_features, dem_features, interaction_features
        )

        # æ­¥éª¤4: éªŒè¯æ•°æ®é›†
        log_progress("\nã€é˜¶æ®µ4/4ã€‘éªŒè¯ä¿å­˜çš„æ•°æ®é›†")
        verify_final_datasets()

        # æœ€ç»ˆæ€»ç»“
        print("\n" + "=" * 100)
        print("å¤„ç†å®Œæˆï¼".center(100))
        print("=" * 100)

        print("\nğŸ“Š æœ€ç»ˆæ•°æ®é›†ç»“æ„:")
        print(f"\nè®­ç»ƒé›† (train.nc):")
        print(train_ds)

        print(f"\néªŒè¯é›† (val.nc):")
        print(val_ds)

        print(f"\næµ‹è¯•é›† (test.nc):")
        print(test_ds)

        print("\nâœ… ç‰¹å¾æ„æˆ:")
        print(f"   1. TIGGEæ°”è±¡ç‰¹å¾ ({len(tigge_features)}ä¸ª):")
        for i, feat in enumerate(tigge_features, 1):
            print(f"      {i:2d}. {feat}")

        print(f"\n   2. DEMåœ°å½¢ç‰¹å¾ ({len(dem_features)}ä¸ª):")
        for i, feat in enumerate(dem_features, 1):
            print(f"      {i}. {feat}")

        print(f"\n   3. ç‰©ç†äº¤äº’ç‰¹å¾ ({len(interaction_features)}ä¸ª):")
        for i, feat in enumerate(interaction_features, 1):
            print(f"      {i}. {feat}")
            # æ·»åŠ ç‰©ç†æ„ä¹‰è¯´æ˜
            if feat == 'wind_terrain_drag':
                print(f"         â†’ ç‰©ç†æ„ä¹‰: åœ°å½¢ç²—ç³™åº¦å¯¹é£é€Ÿçš„é˜»åŠ›æ•ˆåº”")
            elif feat == 'wind_aspect_coupling':
                print(f"         â†’ ç‰©ç†æ„ä¹‰: é£é€ŸçŸ¢é‡ä¸åœ°å½¢æœå‘çš„è€¦åˆ")
            elif feat == 'thermal_lapse':
                print(f"         â†’ ç‰©ç†æ„ä¹‰: æ¸©åº¦éšæµ·æ‹”çš„å‚ç›´é€’å‡")
            elif feat == 'pressure_elevation':
                print(f"         â†’ ç‰©ç†æ„ä¹‰: æ°”å‹éšæµ·æ‹”çš„æŒ‡æ•°è¡°å‡")
            elif feat == 'radiation_aspect':
                print(f"         â†’ ç‰©ç†æ„ä¹‰: å¡å‘å¯¹å¤ªé˜³è¾å°„çš„è°ƒåˆ¶")

        print(f"\n   4. æ—¶é—´ç‰¹å¾ (5ä¸ª):")
        print(f"      1. year")
        print(f"      2. month")
        print(f"      3. day")
        print(f"      4. hour")
        print(f"      5. season")

        print(f"\n   æ€»ç‰¹å¾æ•°: {len(tigge_features) + len(dem_features) + len(interaction_features) + 5}")

        print("\nğŸ“ è¾“å‡ºæ–‡ä»¶ä½ç½®:")
        print(f"   æ•°æ®é›†ç›®å½•: {output_path}")
        print(f"   - train.nc (è®­ç»ƒé›†)")
        print(f"   - val.nc (éªŒè¯é›†)")
        print(f"   - test.nc (æµ‹è¯•é›†)")
        print(f"   - tigge_feature_scaler.pkl (TIGGEæ ‡å‡†åŒ–å™¨)")
        print(f"   - dem_feature_scaler.pkl (DEMæ ‡å‡†åŒ–å™¨)")
        print(f"   - interaction_feature_scaler.pkl (äº¤äº’ç‰¹å¾æ ‡å‡†åŒ–å™¨)")
        print(f"   - target_scaler.pkl (ç›®æ ‡å˜é‡æ ‡å‡†åŒ–å™¨)")

        print("\nğŸ¯ ä¸‹ä¸€æ­¥æ“ä½œå»ºè®®:")
        print("   1. ä½¿ç”¨æ ‡å‡†åŒ–å™¨å¯¹æ–°æ•°æ®è¿›è¡Œé¢„å¤„ç†")
        print("   2. æ„å»ºæ·±åº¦å­¦ä¹ æ¨¡å‹ï¼ˆå¦‚Transformerã€LSTMç­‰ï¼‰")
        print("   3. è®­ç»ƒæ¨¡å‹æ—¶å¯åˆ†åˆ«ä½¿ç”¨ä¸‰ç±»ç‰¹å¾æˆ–ç»„åˆä½¿ç”¨")
        print("   4. è¯„ä¼°ç‰©ç†äº¤äº’ç‰¹å¾å¯¹é¢„æµ‹æ€§èƒ½çš„è´¡çŒ®")

        print("\nâ±ï¸  æ€»å¤„ç†æ—¶é—´:")
        total_time = time.time() - total_start_time
        hours = int(total_time // 3600)
        minutes = int((total_time % 3600) // 60)
        seconds = int(total_time % 60)
        print(f"   {hours}å°æ—¶ {minutes}åˆ†é’Ÿ {seconds}ç§’")

        print("\n" + "=" * 100)
        print_memory_usage("å¤„ç†å®Œæˆå")

    except Exception as e:
        print(f"\nâŒ å¤„ç†è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
        raise


if __name__ == "__main__":
    main()