# -*- coding: utf-8 -*-

import os
import numpy as np
import xarray as xr
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler
import joblib
import gc
import time
from datetime import datetime
from pathlib import Path


# ==================== è¾…åŠ©å‡½æ•° ====================
def log_progress(message, start_time=None):
    """è®°å½•è¿›åº¦ä¿¡æ¯"""
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    if start_time:
        elapsed = time.time() - start_time
        elapsed_min = elapsed // 60
        elapsed_sec = elapsed % 60
        print(f"[{timestamp}] {message} (è€—æ—¶: {int(elapsed_min)}åˆ†{int(elapsed_sec)}ç§’)")
    else:
        print(f"[{timestamp}] {message}")
    return time.time()


def print_memory_usage(label=""):
    """æ‰“å°å½“å‰å†…å­˜ä½¿ç”¨æƒ…å†µ"""
    import psutil
    process = psutil.Process(os.getpid())
    memory_info = process.memory_info()
    memory_gb = memory_info.rss / (1024 * 1024 * 1024)
    print(f"å†…å­˜ä½¿ç”¨ {label}: {memory_gb:.2f} GB")


# ==================== ç‰©ç†äº¤äº’ç‰¹å¾æ„å»º ====================
def build_physics_based_interactions(tigge_df, dem_df):
    
   
    aspect_rad = np.deg2rad(dem_df['aspect'].values)
    u10 = tigge_df['u10'].values
    v10 = tigge_df['v10'].values

    
    wind_projection = np.sqrt(
        (u10 * np.cos(aspect_rad)) ** 2 +
        (v10 * np.sin(aspect_rad)) ** 2
    )
    interactions['wind_aspect_coupling'] = wind_projection
    print(f"   wind_aspect_coupling: å‡å€¼={wind_projection.mean():.4f}, æ ‡å‡†å·®={wind_projection.std():.4f}")

    
    sp = tigge_df['sp'].values
    elevation = dem_df['elevation'].values

    
    pressure_corrected = sp * np.exp(-elevation / H)
    interactions['pressure_elevation'] = pressure_corrected
    print(f"   pressure_elevation: å‡å€¼={pressure_corrected.mean():.4f}, æ ‡å‡†å·®={pressure_corrected.std():.4f}")
    interactions_df = pd.DataFrame(interactions)

    log_progress(f"ç‰©ç†äº¤äº’ç‰¹å¾æ„å»ºå®Œæˆï¼Œå…±ç”Ÿæˆ {len(interactions)} ä¸ªç‰¹å¾")
    print(f"\näº¤äº’ç‰¹å¾ç»Ÿè®¡æ‘˜è¦:")
    print(interactions_df.describe())

    return interactions_df


# ==================== æ•°æ®åŠ è½½å’Œå¤„ç† ====================
def load_and_process_data():
    """åŠ è½½æ•°æ®å¹¶æ„å»ºäº¤äº’ç‰¹å¾"""
    start_time = time.time()
    log_progress("=" * 100)
    log_progress("å¼€å§‹æ•°æ®åŠ è½½å’Œå¤„ç†æµç¨‹")
    log_progress("=" * 100)
    print_memory_usage("å¤„ç†å‰")

    # 1. åŠ è½½åŸå§‹æ•°æ®
    log_progress("æ­¥éª¤1: åŠ è½½ERA5ã€TIGGEã€DEMæ•°æ®...")
    era5 = xr.open_dataset(input_data_path["ERA5"])
    tigge = xr.open_dataset(input_data_path["TIGGE"])
    dem = xr.open_dataset(input_data_path["DEM"])

    log_progress(f"æ•°æ®åŠ è½½å®Œæˆ:")
    print(f"   ERA5æ—¶é—´èŒƒå›´: {era5.time.values.min()} è‡³ {era5.time.values.max()}")
    print(f"   TIGGEæ—¶é—´èŒƒå›´: {tigge.time.values.min()} è‡³ {tigge.time.values.max()}")
    print(f"   DEMç©ºé—´èŒƒå›´: lat({dem.lat.values.min():.2f}, {dem.lat.values.max():.2f}), "
          f"lon({dem.lon.values.min():.2f}, {dem.lon.values.max():.2f})")

    # 2. åˆå¹¶æ•°æ®é›†
    log_progress("æ­¥éª¤2: åˆå¹¶æ•°æ®é›†...")
    merged = xr.merge([era5, tigge, dem], join='inner')
    print(f"   åˆå¹¶åæ•°æ®å½¢çŠ¶: {dict(merged.dims)}")

    # 3. æŒ‰å¹´ä»½åˆ’åˆ†æ•°æ®
    log_progress("æ­¥éª¤3: æŒ‰å¹´ä»½åˆ’åˆ†æ•°æ®é›†...")
    merged['time'] = pd.to_datetime(merged.time.values)

    train_data = merged.sel(time=slice('2021-01-01', '2022-12-31'))
    val_data = merged.sel(time=slice('2023-01-01', '2023-12-31'))
    test_data = merged.sel(time=slice('2024-01-01', '2024-12-31'))

    print(f"   è®­ç»ƒé›†(2021-2022): {len(train_data.time)} æ—¶é—´ç‚¹")
    print(f"   éªŒè¯é›†(2023): {len(val_data.time)} æ—¶é—´ç‚¹")
    print(f"   æµ‹è¯•é›†(2024): {len(test_data.time)} æ—¶é—´ç‚¹")

    # 4. è½¬æ¢ä¸ºDataFrame
    log_progress("æ­¥éª¤4: è½¬æ¢ä¸ºDataFrameæ ¼å¼...")
    train_df = train_data.to_dataframe().reset_index().dropna(subset=['era5_wind_speed'])
    val_df = val_data.to_dataframe().reset_index().dropna(subset=['era5_wind_speed'])
    test_df = test_data.to_dataframe().reset_index().dropna(subset=['era5_wind_speed'])

    print(f"   è®­ç»ƒé›†æ ·æœ¬æ•°: {len(train_df)}")
    print(f"   éªŒè¯é›†æ ·æœ¬æ•°: {len(val_df)}")
    print(f"   æµ‹è¯•é›†æ ·æœ¬æ•°: {len(test_df)}")

    # é‡Šæ”¾å†…å­˜
    del merged, train_data, val_data, test_data, era5
    gc.collect()
    print_memory_usage("DataFrameè½¬æ¢å")

    log_progress("æ•°æ®åŠ è½½å’Œå¤„ç†å®Œæˆ", start_time)
    return train_df, val_df, test_df, tigge, dem


def extract_and_standardize_features(train_df, val_df, test_df, tigge, dem):
    """æå–ç‰¹å¾ã€æ„å»ºäº¤äº’ç‰¹å¾å¹¶æ ‡å‡†åŒ–"""
    start_time = time.time()
    log_progress("=" * 100)
    log_progress("å¼€å§‹ç‰¹å¾æå–å’Œæ ‡å‡†åŒ–")
    log_progress("=" * 100)

    # 1. å®šä¹‰ç‰¹å¾åˆ—è¡¨
    log_progress("æ­¥éª¤1: å®šä¹‰ç‰¹å¾åˆ—è¡¨...")

    # 2. æ„å»ºç‰©ç†äº¤äº’ç‰¹å¾
    log_progress("æ­¥éª¤2: æ„å»ºç‰©ç†äº¤äº’ç‰¹å¾...")

    train_interactions = build_physics_based_interactions(
        train_df[tigge_features], train_df[dem_features]
    )
    val_interactions = build_physics_based_interactions(
        val_df[tigge_features], val_df[dem_features]
    )
    test_interactions = build_physics_based_interactions(
        test_df[tigge_features], test_df[dem_features]
    )

    interaction_features = list(train_interactions.columns)
    print(f"   ç”Ÿæˆäº¤äº’ç‰¹å¾: {len(interaction_features)}ä¸ª")
    for i, feat in enumerate(interaction_features, 1):
        print(f"      {i}. {feat}")

    # 3. æ ‡å‡†åŒ–TIGGEç‰¹å¾
    log_progress("æ­¥éª¤3: æ ‡å‡†åŒ–TIGGEç‰¹å¾...")
    scaler_tigge = MinMaxScaler(feature_range=(0, 1))

    X_train_tigge = scaler_tigge.fit_transform(train_df[tigge_features].fillna(0))
    X_val_tigge = scaler_tigge.transform(val_df[tigge_features].fillna(0))
    X_test_tigge = scaler_tigge.transform(test_df[tigge_features].fillna(0))

    print(f"   TIGGEç‰¹å¾æ ‡å‡†åŒ–å®Œæˆ: {X_train_tigge.shape}")

    # 4. æ ‡å‡†åŒ–DEMç‰¹å¾
    log_progress("æ­¥éª¤4: æ ‡å‡†åŒ–DEMç‰¹å¾...")
    scaler_dem = MinMaxScaler(feature_range=(0, 1))

    X_train_dem = scaler_dem.fit_transform(train_df[dem_features].fillna(0))
    X_val_dem = scaler_dem.transform(val_df[dem_features].fillna(0))
    X_test_dem = scaler_dem.transform(test_df[dem_features].fillna(0))

    print(f"   DEMç‰¹å¾æ ‡å‡†åŒ–å®Œæˆ: {X_train_dem.shape}")

    # 5. æ ‡å‡†åŒ–äº¤äº’ç‰¹å¾
    log_progress("æ­¥éª¤5: æ ‡å‡†åŒ–äº¤äº’ç‰¹å¾...")
    scaler_interaction = MinMaxScaler(feature_range=(0, 1))

    X_train_interaction = scaler_interaction.fit_transform(train_interactions)
    X_val_interaction = scaler_interaction.transform(val_interactions)
    X_test_interaction = scaler_interaction.transform(test_interactions)

    print(f"   äº¤äº’ç‰¹å¾æ ‡å‡†åŒ–å®Œæˆ: {X_train_interaction.shape}")

    # 6. æ ‡å‡†åŒ–ç›®æ ‡å˜é‡
    log_progress("æ­¥éª¤6: æ ‡å‡†åŒ–ç›®æ ‡å˜é‡...")
    scaler_y = MinMaxScaler(feature_range=(0, 1))

    y_train = scaler_y.fit_transform(train_df['era5_wind_speed'].values.reshape(-1, 1)).flatten()
    y_val = scaler_y.transform(val_df['era5_wind_speed'].values.reshape(-1, 1)).flatten()
    y_test = scaler_y.transform(test_df['era5_wind_speed'].values.reshape(-1, 1)).flatten()

    print(f"   ç›®æ ‡å˜é‡æ ‡å‡†åŒ–å®Œæˆ: {y_train.shape}")

    # 7. å¤„ç†æ—¶é—´ç‰¹å¾
    log_progress("æ­¥éª¤7: å¤„ç†æ—¶é—´ç‰¹å¾...")
    time_features_dict = {}

    for phase, df in [('train', train_df), ('val', val_df), ('test', test_df)]:
        df['time'] = pd.to_datetime(df['time'])
        time_cols = pd.DataFrame({
            'year': df['time'].dt.year,
            'month': df['time'].dt.month,
            'day': df['time'].dt.day,
            'hour': df['time'].dt.hour,
            'season': df['time'].dt.month % 12 // 3 + 1
        })
        time_features_dict[phase] = time_cols.values.astype(np.int64)

    print(f"   æ—¶é—´ç‰¹å¾æå–å®Œæˆ")

    # 8. ä¿å­˜æ ‡å‡†åŒ–å™¨
    log_progress("æ­¥éª¤8: ä¿å­˜æ ‡å‡†åŒ–å™¨...")

    print(f"   æ ‡å‡†åŒ–å™¨å·²ä¿å­˜è‡³: {output_path}")

    # é‡Šæ”¾å†…å­˜
    del train_df, val_df, test_df
    gc.collect()
    print_memory_usage("ç‰¹å¾æå–å")

    log_progress("ç‰¹å¾æå–å’Œæ ‡å‡†åŒ–å®Œæˆ", start_time)

    return (X_train_tigge, X_val_tigge, X_test_tigge,
            X_train_dem, X_val_dem, X_test_dem,
            X_train_interaction, X_val_interaction, X_test_interaction,
            y_train, y_val, y_test,
            time_features_dict,
            tigge_features, dem_features, interaction_features)


def save_final_datasets(X_train_tigge, X_val_tigge, X_test_tigge,
                        X_train_dem, X_val_dem, X_test_dem,
                        X_train_interaction, X_val_interaction, X_test_interaction,
                        y_train, y_val, y_test,
                        time_features_dict,
                        tigge_features, dem_features, interaction_features):
    """ä¿å­˜æœ€ç»ˆæ•°æ®é›†ä¸ºNetCDFæ ¼å¼"""
    start_time = time.time()
    log_progress("=" * 100)
    log_progress("å¼€å§‹ä¿å­˜æœ€ç»ˆæ•°æ®é›†")
    log_progress("=" * 100)

    # æ•°æ®ç»´åº¦éªŒè¯
    log_progress("æ­¥éª¤1: éªŒè¯æ•°æ®ç»´åº¦...")
    print(f"   TIGGEç‰¹å¾: Train{X_train_tigge.shape}, Val{X_val_tigge.shape}, Test{X_test_tigge.shape}")
    print(f"   DEMç‰¹å¾: Train{X_train_dem.shape}, Val{X_val_dem.shape}, Test{X_test_dem.shape}")
    print(
        f"   äº¤äº’ç‰¹å¾: Train{X_train_interaction.shape}, Val{X_val_interaction.shape}, Test{X_test_interaction.shape}")
    print(f"   ç›®æ ‡å˜é‡: Train{y_train.shape}, Val{y_val.shape}, Test{y_test.shape}")

    time_feature_labels = ['year', 'month', 'day', 'hour', 'season']

    # åˆ›å»ºè®­ç»ƒé›†
    log_progress("æ­¥éª¤2: åˆ›å»ºè®­ç»ƒé›†æ•°æ®é›†...")
    train_ds = xr.Dataset(
        data_vars={
            "tigge_features": (["sample", "tigge_feature"], X_train_tigge),
            "dem_features": (["sample", "dem_feature"], X_train_dem),
            "interaction_features": (["sample", "interaction_feature"], X_train_interaction),
            "target": (["sample"], y_train),
            "time_features": (["sample", "time_feature"], time_features_dict['train'])
        },
        coords={
            "sample": np.arange(X_train_tigge.shape[0]),
            "tigge_feature": tigge_features,
            "dem_feature": dem_features,
            "interaction_feature": interaction_features,
            "time_feature": time_feature_labels
        },
        attrs={
            "description": "è®­ç»ƒé›†æ•°æ®ï¼ˆ2021-2022ï¼‰",
            "created_date": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "tigge_features_count": len(tigge_features),
            "dem_features_count": len(dem_features),
            "interaction_features_count": len(interaction_features),
            "total_samples": X_train_tigge.shape[0]
        }
    )

    # åˆ›å»ºéªŒè¯é›†
    log_progress("æ­¥éª¤3: åˆ›å»ºéªŒè¯é›†æ•°æ®é›†...")
    val_ds = xr.Dataset(
        data_vars={
            "tigge_features": (["sample", "tigge_feature"], X_val_tigge),
            "dem_features": (["sample", "dem_feature"], X_val_dem),
            "interaction_features": (["sample", "interaction_feature"], X_val_interaction),
            "target": (["sample"], y_val),
            "time_features": (["sample", "time_feature"], time_features_dict['val'])
        },
        coords={
            "sample": np.arange(X_val_tigge.shape[0]),
            "tigge_feature": tigge_features,
            "dem_feature": dem_features,
            "interaction_feature": interaction_features,
            "time_feature": time_feature_labels
        },
        attrs={
            "description": "éªŒè¯é›†æ•°æ®ï¼ˆ2023ï¼‰",
            "created_date": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "tigge_features_count": len(tigge_features),
            "dem_features_count": len(dem_features),
            "interaction_features_count": len(interaction_features),
            "total_samples": X_val_tigge.shape[0]
        }
    )

    # åˆ›å»ºæµ‹è¯•é›†
    log_progress("æ­¥éª¤4: åˆ›å»ºæµ‹è¯•é›†æ•°æ®é›†...")
    test_ds = xr.Dataset(
        data_vars={
            "tigge_features": (["sample", "tigge_feature"], X_test_tigge),
            "dem_features": (["sample", "dem_feature"], X_test_dem),
            "interaction_features": (["sample", "interaction_feature"], X_test_interaction),
            "target": (["sample"], y_test),
            "time_features": (["sample", "time_feature"], time_features_dict['test'])
        },
        coords={
            "sample": np.arange(X_test_tigge.shape[0]),
            "tigge_feature": tigge_features,
            "dem_feature": dem_features,
            "interaction_feature": interaction_features,
            "time_feature": time_feature_labels
        },
        attrs={
            "description": "æµ‹è¯•é›†æ•°æ®ï¼ˆ2024ï¼‰",
            "created_date": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "tigge_features_count": len(tigge_features),
            "dem_features_count": len(dem_features),
            "interaction_features_count": len(interaction_features),
            "total_samples": X_test_tigge.shape[0]
        }
    )

    # ä¿å­˜æ•°æ®é›†
    try:
        log_progress("æ­¥éª¤5: ä¿å­˜æ•°æ®é›†åˆ°ç£ç›˜...")

        train_file = output_path / "train.nc"
        val_file = output_path / "val.nc"
        test_file = output_path / "test.nc"

        train_ds.to_netcdf(train_file)
        print(f"   âœ“ è®­ç»ƒé›†å·²ä¿å­˜: {train_file}")

        val_ds.to_netcdf(val_file)
        print(f"   âœ“ éªŒè¯é›†å·²ä¿å­˜: {val_file}")

        test_ds.to_netcdf(test_file)
        print(f"   âœ“ æµ‹è¯•é›†å·²ä¿å­˜: {test_file}")

        # è¾“å‡ºæ–‡ä»¶å¤§å°
        train_size = train_file.stat().st_size / (1024 ** 2)
        val_size = val_file.stat().st_size / (1024 ** 2)
        test_size = test_file.stat().st_size / (1024 ** 2)

        print(f"\n   æ–‡ä»¶å¤§å°:")
        print(f"      train.nc: {train_size:.2f} MB")
        print(f"      val.nc: {val_size:.2f} MB")
        print(f"      test.nc: {test_size:.2f} MB")
        print(f"      æ€»è®¡: {train_size + val_size + test_size:.2f} MB")

    except Exception as e:
        print(f"   âœ— ä¿å­˜æ•°æ®é›†æ—¶å‡ºé”™: {e}")
        raise

    log_progress("æ•°æ®é›†ä¿å­˜å®Œæˆ", start_time)

    return train_ds, val_ds, test_ds


def verify_final_datasets():
    """éªŒè¯ä¿å­˜çš„æ•°æ®é›†"""
    log_progress("=" * 100)
    log_progress("éªŒè¯ä¿å­˜çš„æ•°æ®é›†")
    log_progress("=" * 100)

    datasets = {
        "è®­ç»ƒé›†": output_path / "train.nc",
        "éªŒè¯é›†": output_path / "val.nc",
        "æµ‹è¯•é›†": output_path / "test.nc"
    }

    for name, path in datasets.items():
        print(f"\n{'=' * 80}")
        print(f"æ­£åœ¨éªŒè¯: {name}")
        print(f"{'=' * 80}")

        if not path.exists():
            print(f"   âœ— æ–‡ä»¶ä¸å­˜åœ¨: {path}")
            continue

        ds = xr.open_dataset(path)

    log_progress("æ•°æ®é›†éªŒè¯å®Œæˆ")


# ==================== ä¸»æµç¨‹ ====================
def main():
    """ä¸»æµç¨‹å‡½æ•°"""
    total_start_time = time.time()

    print("\n" + "=" * 100)
    print("åŸºäºç‰©ç†è§„å¾‹çš„æ°”è±¡-åœ°å½¢äº¤äº’ç‰¹å¾æ„å»ºç³»ç»Ÿ".center(100))
    print("=" * 100)
    log_progress(f"å¼€å§‹æ‰§è¡Œ - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

    try:
        # æ­¥éª¤1: åŠ è½½å’Œå¤„ç†æ•°æ®
        log_progress("\nã€é˜¶æ®µ1/4ã€‘æ•°æ®åŠ è½½å’Œé¢„å¤„ç†")
        train_df, val_df, test_df, tigge, dem = load_and_process_data()

        # æ­¥éª¤2: æå–ç‰¹å¾ã€æ„å»ºäº¤äº’ç‰¹å¾å¹¶æ ‡å‡†åŒ–
        log_progress("\nã€é˜¶æ®µ2/4ã€‘ç‰¹å¾æå–å’Œæ ‡å‡†åŒ–")
        (X_train_tigge, X_val_tigge, X_test_tigge,
         X_train_dem, X_val_dem, X_test_dem,
         X_train_interaction, X_val_interaction, X_test_interaction,
         y_train, y_val, y_test,
         time_features_dict,
         tigge_features, dem_features, interaction_features) = extract_and_standardize_features(
            train_df, val_df, test_df, tigge, dem
        )

        # æ­¥éª¤3: ä¿å­˜æœ€ç»ˆæ•°æ®é›†
        log_progress("\nã€é˜¶æ®µ3/4ã€‘ä¿å­˜æœ€ç»ˆæ•°æ®é›†")
        train_ds, val_ds, test_ds = save_final_datasets(
            X_train_tigge, X_val_tigge, X_test_tigge,
            X_train_dem, X_val_dem, X_test_dem,
            X_train_interaction, X_val_interaction, X_test_interaction,
            y_train, y_val, y_test,
            time_features_dict,
            tigge_features, dem_features, interaction_features
        )

        # æ­¥éª¤4: éªŒè¯æ•°æ®é›†
        log_progress("\nã€é˜¶æ®µ4/4ã€‘éªŒè¯ä¿å­˜çš„æ•°æ®é›†")
        verify_final_datasets()

        # æœ€ç»ˆæ€»ç»“
        print("\n" + "=" * 100)
        print("å¤„ç†å®Œæˆï¼".center(100))
        print("=" * 100)

        print("\nğŸ“Š æœ€ç»ˆæ•°æ®é›†ç»“æ„:")
        print(f"\nè®­ç»ƒé›† (train.nc):")
        print(train_ds)

        print(f"\néªŒè¯é›† (val.nc):")
        print(val_ds)

        print(f"\næµ‹è¯•é›† (test.nc):")
        print(test_ds)

        print("\nâœ… ç‰¹å¾æ„æˆ:")
        print(f"   1. TIGGEæ°”è±¡ç‰¹å¾ ({len(tigge_features)}ä¸ª):")
        for i, feat in enumerate(tigge_features, 1):
            print(f"      {i:2d}. {feat}")

        print(f"\n   2. DEMåœ°å½¢ç‰¹å¾ ({len(dem_features)}ä¸ª):")
        for i, feat in enumerate(dem_features, 1):
            print(f"      {i}. {feat}")

        print(f"\n   3. ç‰©ç†äº¤äº’ç‰¹å¾ ({len(interaction_features)}ä¸ª):")
        for i, feat in enumerate(interaction_features, 1):
            print(f"      {i}. {feat}")
            # æ·»åŠ ç‰©ç†æ„ä¹‰è¯´æ˜
            if feat == 'wind_terrain_drag':
                print(f"         â†’ ç‰©ç†æ„ä¹‰: åœ°å½¢ç²—ç³™åº¦å¯¹é£é€Ÿçš„é˜»åŠ›æ•ˆåº”")
            elif feat == 'wind_aspect_coupling':
                print(f"         â†’ ç‰©ç†æ„ä¹‰: é£é€ŸçŸ¢é‡ä¸åœ°å½¢æœå‘çš„è€¦åˆ")
            elif feat == 'thermal_lapse':
                print(f"         â†’ ç‰©ç†æ„ä¹‰: æ¸©åº¦éšæµ·æ‹”çš„å‚ç›´é€’å‡")
            elif feat == 'pressure_elevation':
                print(f"         â†’ ç‰©ç†æ„ä¹‰: æ°”å‹éšæµ·æ‹”çš„æŒ‡æ•°è¡°å‡")
            elif feat == 'radiation_aspect':
                print(f"         â†’ ç‰©ç†æ„ä¹‰: å¡å‘å¯¹å¤ªé˜³è¾å°„çš„è°ƒåˆ¶")

        print(f"\n   4. æ—¶é—´ç‰¹å¾ (5ä¸ª):")
        print(f"      1. year")
        print(f"      2. month")
        print(f"      3. day")
        print(f"      4. hour")
        print(f"      5. season")

        print(f"\n   æ€»ç‰¹å¾æ•°: {len(tigge_features) + len(dem_features) + len(interaction_features) + 5}")
        
    except Exception as e:
        print(f"\nâŒ å¤„ç†è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
        raise


if __name__ == "__main__":
    main()